{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b9d7ba",
   "metadata": {},
   "source": [
    "# 03 - Topic Modeling Training\n",
    "\n",
    "This notebook performs topic modeling on the preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b71e9",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a12bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel, LdaModel, TfidfModel\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from gensim.matutils import corpus2csc\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "from joblib import Parallel, delayed\n",
    "from plotly import express as px\n",
    "from pprint import pformat\n",
    "\n",
    "from src.topic_model_utils import evaluate_topic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cfb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data():\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    # Load your data here\n",
    "    df = pd.read_json('../data/processed/data_processed.json', lines=True)\n",
    "    # Preprocessing steps...\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35aa9c9",
   "metadata": {},
   "source": [
    "## 2. Topic Modeling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_parallel(num_topics_range, corpus, corpus_tfidf_sparse, dictionary, processed_texts, save_dir=None, save_models=False):\n",
    "    with tqdm_joblib(tqdm(total=len(num_topics_range), desc=\"Evaluating models\")):\n",
    "        results = Parallel(n_jobs=-1, prefer=\"processes\")(\n",
    "            delayed(evaluate_topic_models)(\n",
    "                num_topics, corpus, corpus_tfidf_sparse, dictionary, processed_texts, save_dir, save_models\n",
    "            )\n",
    "            for num_topics in num_topics_range\n",
    "        )\n",
    "    coherence_df = pd.DataFrame(results, columns=[\"num_topics\", \"results\"]).sort_values(by=\"num_topics\").reset_index(drop=True)\n",
    "    return coherence_df\n",
    "\n",
    "\n",
    "def evaluate_models_serial(num_topics_range, corpus, corpus_tfidf_sparse, dictionary, processed_texts, save_dir=None, save_models=False):\n",
    "    results = []\n",
    "    for num_topics in tqdm(num_topics_range, desc=\"Evaluating models\"):\n",
    "        result = evaluate_topic_models(num_topics, corpus, corpus_tfidf_sparse, dictionary, processed_texts, save_dir, save_models)\n",
    "        results.append(result)\n",
    "    coherence_df = pd.DataFrame(results, columns=[\"num_topics\", \"results\"]).sort_values(by=\"num_topics\").reset_index(drop=True)\n",
    "    return coherence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary and corpus\n",
    "dictionary = corpora.Dictionary(df[\"processed_text\"])\n",
    "corpus = [dictionary.doc2bow(text) for text in df[\"processed_text\"]]\n",
    "\n",
    "# Transforming to TF-IDF for LSA and pLSA\n",
    "tfidf_model = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all necessary components\n",
    "dictionary = corpora.Dictionary(df[\"processed_text\"])\n",
    "dictionary.save(\"../data/processed/dictionary.dict\")\n",
    "joblib.dump(dictionary, \"../data/processed/dictionary.joblib\")\n",
    "\n",
    "# Save the TF-IDF model\n",
    "tfidf_model = TfidfModel(corpus)\n",
    "joblib.dump(tfidf_model, \"../data/processed/tfidf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting corpus_tfidf to sparse matrix\n",
    "corpus_tfidf_sparse = corpus2csc(corpus_tfidf).T\n",
    "\n",
    "# Defining topic range\n",
    "num_topics_range = range(3, 16)\n",
    "\n",
    "# Evaluating models serially\n",
    "coherence_df = evaluate_models_serial(num_topics_range, corpus, corpus_tfidf_sparse, dictionary, df[\"processed_text\"])\n",
    "\n",
    "# Printing results\n",
    "print(coherence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save coherence results as a CSV file\n",
    "coherence_df.to_csv(\"../data/processed/coherence_results.csv\", index=False)\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    return val\n",
    "\n",
    "coherence_df['results'] = coherence_df['results'].apply(safe_literal_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a48f9",
   "metadata": {},
   "source": [
    "## 3. Analysis of Topic Models and Coherence Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dict into separate columns\n",
    "results_expanded = pd.json_normalize(coherence_df['results'])\n",
    "coherence_df = pd.concat([coherence_df.drop(columns=['results']), results_expanded], axis=1)\n",
    "\n",
    "print(coherence_df)\n",
    "print(coherence_df.iloc[0])\n",
    "print(coherence_df.iloc[0]['coherence_lda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Melt DataFrame for plotting ---\n",
    "coherence_df_long = coherence_df.melt(\n",
    "    id_vars=[\"num_topics\"],\n",
    "    value_vars=[\"coherence_lda\", \"coherence_lsa\", \"coherence_plsa\"],\n",
    "    var_name=\"model\",\n",
    "    value_name=\"coherence\"\n",
    ")\n",
    "\n",
    "# Plot knee plot\n",
    "fig = px.line(\n",
    "    coherence_df_long,\n",
    "    x=\"num_topics\",\n",
    "    y=\"coherence\",\n",
    "    color=\"model\",  # Differentiate lines by model\n",
    "    markers=True,\n",
    "    title=\"Coherence Value vs Number of Topics\",\n",
    "    labels={\"num_topics\": \"Number of Topics\", \"coherence\": \"Coherence Score\", \"model\": \"Model\"}\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Topics\",\n",
    "    yaxis_title=\"Coherence Score\",\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    legend_title=\"Model\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab7334",
   "metadata": {},
   "source": [
    "#### **Analysis of Topic Model Coherence Trends**  \n",
    "\n",
    "- **LDA**: Peaks at **4 topics (0.5169)**, then declines. More topics lead to **topic fragmentation** and reduced coherence.  \n",
    "- **LSA**: Peaks at **3 topics (0.6477)**, then declines. Struggles with **dimensionality reduction loss** at higher topic counts.  \n",
    "- **pLSA**: Steady increase from **2 topics (0.5094) to 15 topics (0.7071)**. Performs better with **more topics**, leveraging **soft topic assignments**.  \n",
    "- **Comparison**:\n",
    "  - **LDA & LSA**: Best with **fewer topics**, decline as topics increase.  \n",
    "  - **pLSA**: **Improves with more topics**, capturing complex structures better.  \n",
    "- **Conclusion**: pLSA outperforms LDA and LSA at higher topic counts, while LDA/LSA are more effective at lower topic numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate average coherence and scores spread ---\n",
    "coherence_df['average_coherence'] = coherence_df[['coherence_lda', 'coherence_lsa', 'coherence_plsa']].mean(axis=1)\n",
    "coherence_df['spread'] = coherence_df[['coherence_lda', 'coherence_lsa', 'coherence_plsa']].max(axis=1) - \\\n",
    "                         coherence_df[['coherence_lda', 'coherence_lsa', 'coherence_plsa']].min(axis=1)\n",
    "\n",
    "# --- Select Best Models ---\n",
    "# Best individual models\n",
    "best_lda = coherence_df.loc[coherence_df['coherence_lda'].idxmax()]\n",
    "best_lsa = coherence_df.loc[coherence_df['coherence_lsa'].idxmax()]\n",
    "best_plsa = coherence_df.loc[coherence_df['coherence_plsa'].idxmax()]\n",
    "\n",
    "# Best overall group based on average coherence\n",
    "best_group = coherence_df.loc[coherence_df['average_coherence'].idxmax()]\n",
    "\n",
    "# Best group with minimum spread (i.e. most similar scores)\n",
    "best_group_spread = coherence_df.loc[coherence_df['spread'].idxmin()]\n",
    "\n",
    "# --- Create Summary DataFrames ---\n",
    "best_individual_df = pd.DataFrame({\n",
    "    'Technique': ['LDA', 'LSA', 'pLSA'],\n",
    "    'Best_Num_Topics': [\n",
    "        best_lda['num_topics'],\n",
    "        best_lsa['num_topics'],\n",
    "        best_plsa['num_topics']\n",
    "    ],\n",
    "    'Best_Coherence': [\n",
    "        best_lda['coherence_lda'],\n",
    "        best_lsa['coherence_lsa'],\n",
    "        best_plsa['coherence_plsa']\n",
    "    ]\n",
    "})\n",
    "\n",
    "best_group_df = pd.DataFrame({\n",
    "    'Strategy': ['Best Average Group'],\n",
    "    'Num_Topics': [best_group['num_topics']],\n",
    "    'Average_Coherence': [best_group['average_coherence']],\n",
    "    'LDA_Coherence': [best_group['coherence_lda']],\n",
    "    'LSA_Coherence': [best_group['coherence_lsa']],\n",
    "    'PLSA_Coherence': [best_group['coherence_plsa']]\n",
    "})\n",
    "\n",
    "best_group_spread_df = pd.DataFrame({\n",
    "    'Strategy': ['Minimum Spread Group'],\n",
    "    'Num_Topics': [best_group_spread['num_topics']],\n",
    "    'Spread': [best_group_spread['spread']],\n",
    "    'LDA_Coherence': [best_group_spread['coherence_lda']],\n",
    "    'LSA_Coherence': [best_group_spread['coherence_lsa']],\n",
    "    'PLSA_Coherence': [best_group_spread['coherence_plsa']]\n",
    "})\n",
    "\n",
    "# --- Load Models ---\n",
    "# Load individual best models\n",
    "num_topics_lda = int(best_lda['num_topics'])\n",
    "best_lda_model = joblib.load(f\"models/lda_model_{num_topics_lda}.pkl\")\n",
    "\n",
    "num_topics_lsa = int(best_lsa['num_topics'])\n",
    "best_lsa_model = joblib.load(f\"models/lsa_model_{num_topics_lsa}.pkl\")\n",
    "\n",
    "num_topics_plsa = int(best_plsa['num_topics'])\n",
    "best_plsa_model = joblib.load(f\"models/plsa_model_{num_topics_plsa}.pkl\")\n",
    "\n",
    "# Load best group models (by average coherence)\n",
    "num_topics_group = int(best_group['num_topics'])\n",
    "best_group_lda = joblib.load(f\"models/lda_model_{num_topics_group}.pkl\")\n",
    "best_group_lsa = joblib.load(f\"models/lsa_model_{num_topics_group}.pkl\")\n",
    "best_group_plsa = joblib.load(f\"models/plsa_model_{num_topics_group}.pkl\")\n",
    "\n",
    "# Optionally, load the best minimum spread group models (if different)\n",
    "num_topics_group_spread = int(best_group_spread['num_topics'])\n",
    "best_group_spread_lda = joblib.load(f\"models/lda_model_{num_topics_group_spread}.pkl\")\n",
    "best_group_spread_lsa = joblib.load(f\"models/lsa_model_{num_topics_group_spread}.pkl\")\n",
    "best_group_spread_plsa = joblib.load(f\"models/plsa_model_{num_topics_group_spread}.pkl\")\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"Best Individual Models:\")\n",
    "print(best_individual_df)\n",
    "print(\"\\nBest Group Model (Average Coherence):\")\n",
    "print(best_group_df)\n",
    "print(\"\\nBest Group Model (Minimum Spread):\")\n",
    "print(best_group_spread_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the original line plot\n",
    "fig = px.line(\n",
    "    coherence_df_long,\n",
    "    x=\"num_topics\",\n",
    "    y=\"coherence\",\n",
    "    color=\"model\",  # Differentiates lines by model\n",
    "    markers=True,\n",
    "    title=\"Coherence Value vs Number of Topics\",\n",
    "    labels={\"num_topics\": \"Number of Topics\", \"coherence\": \"Coherence Score\", \"model\": \"Model\"}\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Topics\",\n",
    "    yaxis_title=\"Coherence Score\",\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    legend_title=\"Model\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Highlight the groups using vertical lines.\n",
    "# Make sure num_topics_group and num_topics_group_spread are defined from your analysis.\n",
    "fig.add_vline(\n",
    "    x=num_topics_group,\n",
    "    line=dict(dash=\"dash\", color=\"black\"),\n",
    "    annotation_text=\"Best Group (Avg)\",\n",
    "    annotation_position=\"top left\"\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=num_topics_group_spread,\n",
    "    line=dict(dash=\"dash\", color=\"orange\"),\n",
    "    annotation_text=\"Best Group (Spread)\",\n",
    "    annotation_position=\"top right\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "def get_topic_words(model, model_type, dictionary, n_words=10):\n",
    "    \"\"\"Extract the top words for each topic for different model types.\"\"\"\n",
    "    topics = []\n",
    "    if model_type == 'LDA':\n",
    "        for idx in range(model.num_topics):\n",
    "            topics.append([word for word, _ in model.show_topic(idx, topn=n_words)])\n",
    "    elif model_type in ['LSA', 'pLSA']:\n",
    "        for topic in model.components_:\n",
    "            top_indices = topic.argsort()[-n_words:][::-1]\n",
    "            # Use dictionary[i] to retrieve the token. If a key is missing, mark it as unknown.\n",
    "            tokens = []\n",
    "            for i in top_indices:\n",
    "                try:\n",
    "                    tokens.append(dictionary[i])\n",
    "                except KeyError:\n",
    "                    tokens.append(f\"<UNK:{i}>\")\n",
    "            topics.append(tokens)\n",
    "    return topics\n",
    "\n",
    "\n",
    "def print_topics(topics, model_name):\n",
    "    \"\"\"Print topics in a formatted manner.\"\"\"\n",
    "    print(f\"\\nTópicos para {model_name}:\")\n",
    "    for i, topic in enumerate(topics, 1):\n",
    "        print(f\"Tópico {i}: {', '.join(topic)}\")\n",
    "\n",
    "def classify_documents(model, model_type, corpus, corpus_tfidf_sparse):\n",
    "    \"\"\"Classify documents into topics.\"\"\"\n",
    "    doc_topics = []\n",
    "    if model_type == 'LDA':\n",
    "        for doc in corpus:\n",
    "            topics = model.get_document_topics(doc)\n",
    "            doc_topics.append(max(topics, key=lambda x: x[1])[0])\n",
    "    elif model_type in ['LSA', 'pLSA']:\n",
    "        transformed = model.transform(corpus_tfidf_sparse)\n",
    "        doc_topics = transformed.argmax(axis=1)\n",
    "    return doc_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b10a46",
   "metadata": {},
   "source": [
    "## 4. Analysis Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens (or creates) the Markdown file for writing\n",
    "with open(\"data/analise.md\", \"w\", encoding=\"utf-8\") as md:\n",
    "    md.write(\"# Análise dos Modelos de Tópicos\\n\\n\")\n",
    "    \n",
    "    # === Análise dos Melhores Modelos Individuais ===\n",
    "    md.write(\"## ANÁLISE DOS MELHORES MODELOS INDIVIDUAIS\\n\")\n",
    "    for technique, model in zip(\n",
    "        ['LDA', 'LSA', 'pLSA'],\n",
    "        [best_lda_model, best_lsa_model, best_plsa_model]\n",
    "    ):\n",
    "        best_num_topics = int(best_individual_df.loc[best_individual_df['Technique'] == technique, 'Best_Num_Topics'].values[0])\n",
    "        md.write(f\"\\n### {technique} (Best Individual – {best_num_topics} tópicos)\\n\")\n",
    "        \n",
    "        topics = get_topic_words(model, technique, dictionary, n_top_words)\n",
    "        md.write(f\"**Palavras-chave ({technique}):**\\n\")\n",
    "        for i, topic in enumerate(topics):\n",
    "            md.write(f\"- Tópico {i+1}: {', '.join(topic[:n_top_words])}\\n\")\n",
    "        \n",
    "        # Classificação dos documentos\n",
    "        if technique == 'LDA':\n",
    "            doc_topics = classify_documents(model, technique, corpus, None)\n",
    "        else:\n",
    "            doc_topics = classify_documents(model, technique, None, corpus_tfidf_sparse)\n",
    "        \n",
    "        topic_dist = pd.Series(doc_topics).value_counts().sort_index()\n",
    "        md.write(f\"\\n**Distribuição de tópicos ({technique}):**\\n\")\n",
    "        md.write(\"```\\n\" + topic_dist.to_string() + \"\\n```\\n\")\n",
    "        \n",
    "        md.write(f\"\\n**Exemplo de classificação de documentos ({technique}):**\\n\")\n",
    "        for i in range(sample_docs):\n",
    "            md.write(f\"\\n**Documento {i+1}:**\\n\")\n",
    "            md.write(\"Texto original:\\n\")\n",
    "            md.write(\"```\\n\" + pformat(df['julgado'].iloc[i]) + \"\\n```\\n\")\n",
    "            md.write(f\"Tópico atribuído: {doc_topics[i] + 1}\\n\")\n",
    "            md.write(f\"Palavras-chave: {', '.join(topics[doc_topics[i]][:n_top_words])}\\n\")\n",
    "    \n",
    "    # === Análise do Melhor Grupo (Average Coherence) ===\n",
    "    md.write(\"\\n## ANÁLISE DO MELHOR GRUPO (AVERAGE COHERENCE)\\n\")\n",
    "    for technique, model in zip(\n",
    "        ['LDA', 'LSA', 'pLSA'],\n",
    "        [best_group_lda, best_group_lsa, best_group_plsa]\n",
    "    ):\n",
    "        md.write(f\"\\n### {technique} (Best Group Average – {num_topics_group} tópicos)\\n\")\n",
    "        \n",
    "        topics = get_topic_words(model, technique, dictionary, n_top_words)\n",
    "        md.write(f\"**Palavras-chave ({technique}):**\\n\")\n",
    "        for i, topic in enumerate(topics):\n",
    "            md.write(f\"- Tópico {i+1}: {', '.join(topic[:n_top_words])}\\n\")\n",
    "        \n",
    "        if technique == 'LDA':\n",
    "            doc_topics = classify_documents(model, technique, corpus, None)\n",
    "        else:\n",
    "            doc_topics = classify_documents(model, technique, None, corpus_tfidf_sparse)\n",
    "        \n",
    "        topic_dist = pd.Series(doc_topics).value_counts().sort_index()\n",
    "        md.write(f\"\\n**Distribuição de tópicos ({technique}):**\\n\")\n",
    "        md.write(\"```\\n\" + topic_dist.to_string() + \"\\n```\\n\")\n",
    "        \n",
    "        md.write(f\"\\n**Exemplo de classificação de documentos ({technique}):**\\n\")\n",
    "        for i in range(sample_docs):\n",
    "            md.write(f\"\\n**Documento {i+1}:**\\n\")\n",
    "            md.write(\"Texto original:\\n\")\n",
    "            md.write(\"```\\n\" + pformat(df['julgado'].iloc[i]) + \"\\n```\\n\")\n",
    "            md.write(f\"Tópico atribuído: {doc_topics[i] + 1}\\n\")\n",
    "            md.write(f\"Palavras-chave: {', '.join(topics[doc_topics[i]][:n_top_words])}\\n\")\n",
    "    \n",
    "    # === Análise do Melhor Grupo (Minimum Spread) ===\n",
    "    md.write(\"\\n## ANÁLISE DO MELHOR GRUPO (MINIMUM SPREAD)\\n\")\n",
    "    for technique, model in zip(\n",
    "        ['LDA', 'LSA', 'pLSA'],\n",
    "        [best_group_spread_lda, best_group_spread_lsa, best_group_spread_plsa]\n",
    "    ):\n",
    "        md.write(f\"\\n### {technique} (Best Group Minimum Spread – {num_topics_group_spread} tópicos)\\n\")\n",
    "        \n",
    "        topics = get_topic_words(model, technique, dictionary, n_top_words)\n",
    "        md.write(f\"**Palavras-chave ({technique}):**\\n\")\n",
    "        for i, topic in enumerate(topics):\n",
    "            md.write(f\"- Tópico {i+1}: {', '.join(topic[:n_top_words])}\\n\")\n",
    "        \n",
    "        if technique == 'LDA':\n",
    "            doc_topics = classify_documents(model, technique, corpus, None)\n",
    "        else:\n",
    "            doc_topics = classify_documents(model, technique, None, corpus_tfidf_sparse)\n",
    "        \n",
    "        topic_dist = pd.Series(doc_topics).value_counts().sort_index()\n",
    "        md.write(f\"\\n**Distribuição de tópicos ({technique}):**\\n\")\n",
    "        md.write(\"```\\n\" + topic_dist.to_string() + \"\\n```\\n\")\n",
    "        \n",
    "        md.write(f\"\\n**Exemplo de classificação de documentos ({technique}):**\\n\")\n",
    "        for i in range(sample_docs):\n",
    "            md.write(f\"\\n**Documento {i+1}:**\\n\")\n",
    "            md.write(\"Texto original:\\n\")\n",
    "            md.write(\"```\\n\" + pformat(df['julgado'].iloc[i]) + \"\\n```\\n\")\n",
    "            md.write(f\"Tópico atribuído: {doc_topics[i] + 1}\\n\")\n",
    "            md.write(f\"Palavras-chave: {', '.join(topics[doc_topics[i]][:n_top_words])}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
